#!/usr/bin/python -u
import argparse
import json
import os
import subprocess
import tempfile
from datetime import datetime
from itertools import cycle
from shutil import get_terminal_size
from threading import Thread
from time import sleep
from typing import TypedDict

import requests
from rich.console import Console
from rich.markdown import Markdown

app_name = "ai-cli"

default_model = "anthropic/claude-3.7-sonnet"
default_attitude = (
    "you are the assistant of a senior backend developer. Answer with markdown."
)


class Loader:
    def __init__(self, desc="Loading...", end="Done!", timeout=0.1):
        self.desc = desc
        self.end = end
        self.timeout = timeout

        self._thread = Thread(target=self._animate, daemon=True)
        self.steps = ["⢿", "⣻", "⣽", "⣾", "⣷", "⣯", "⣟", "⡿"]
        self.done = False

    def start(self):
        self._thread.start()
        return self

    def _animate(self):
        for c in cycle(self.steps):
            if self.done:
                break
            print(f"\r{self.desc} {c}", flush=True, end="")
            sleep(self.timeout)

    def __enter__(self):
        self.start()

    def stop(self):
        self.done = True
        cols = get_terminal_size((80, 20)).columns
        print("\r" + " " * cols, end="", flush=True)
        print(f"\r{self.end}", flush=True)

    def __exit__(self, exc_type, exc_value, tb):
        self.stop()


def get_config_path():
    path = os.path.expandvars(f"$HOME/.config/{app_name}")
    if not os.path.exists(path):
        os.makedirs(path)
    return path


def get_config_path_custom(config_name: str):
    path = get_config_path() + "/" + config_name
    if not os.path.exists(path):
        with open(path, "+w") as file:
            file.write("")
    return path


def get_history_conversation_path():
    return get_config_path_custom("history_conversation")


def get_history_all_path():
    return get_config_path_custom("history_all_time")


def get_attitude_path():
    return get_config_path_custom("attitude")


def get_model_path():
    return get_config_path_custom("model")


def get_api_key_path():
    return get_config_path_custom("api_key")


def get_api_key():
    key = ""
    with open(get_api_key_path(), "r") as f:
        key = f.read()
    key_env = os.environ.get("OPEN_ROUTER_API_KEY")
    if key_env is not None:
        key = key_env
    if key == "":
        print(
            f"Open router api not provided. export OPEN_ROUTER_API_KEY=your_key, or {app_name} -c your_key"
        )
        exit(0)
    return key


class HistoryElement(TypedDict):
    prompt: str
    response: str


def get_attitude() -> str:
    attitude = ""
    with open(get_attitude_path(), "r") as f:
        attitude = f.read()
    if attitude == "":
        attitude = default_attitude
    return attitude


def get_model() -> str:
    model = ""
    with open(get_model_path(), "r") as f:
        model = f.read()
    if model == "":
        model = default_model
    return model


def prompt_ai(
    prompt: str, model: str, attitude: str, history: list[HistoryElement] | None
):
    url = "https://openrouter.ai/api/v1/chat/completions"
    attitude = attitude
    headers = {
        "Authorization": f"Bearer {get_api_key()}",
        "Content-Type": "application/json",
    }
    messages = []
    if attitude != "":
        messages.append({"role": "user", "content": attitude})
    if history is not None:
        for element in history:
            messages.append({"role": "user", "content": element["prompt"]})
            messages.append({"role": "assistant", "content": element["response"]})
    messages.append({"role": "user", "content": prompt})
    payload = {
        "model": model,
        "messages": messages,
        "stream": True,
    }
    buffer = ""
    response = ""

    loader = Loader(f"getting response from {model}...", "", 0.10).start()
    with requests.post(url, headers=headers, json=payload, stream=True) as r:
        for chunk in r.iter_content(chunk_size=1024, decode_unicode=True):
            buffer += chunk
            while True:
                try:
                    line_end = buffer.find("\n")
                    if line_end == -1:
                        break
                    line = buffer[:line_end].strip()
                    buffer = buffer[line_end + 1 :]
                    if line.startswith("data: "):
                        data = line[6:]
                        if data == "[DONE]":
                            break
                        try:
                            data_obj = json.loads(data)
                            content = data_obj["choices"][0]["delta"].get("content")
                            if content:
                                # print(content, end="", flush=True)
                                response += content
                        except json.JSONDecodeError:
                            pass
                except Exception:
                    break
    loader.stop()
    return response


def read_prompt_from_file(file: str) -> str:
    if not os.path.exists(file):
        print(
            f"file {file} does not exitst. create it and write your prompt into it first."
        )
        exit(0)
    with open(file, "r") as f:
        prompt = f.read()
    return prompt


def read_prompt_from_editor() -> str:
    editor = os.environ.get("EDITOR")
    if not editor:
        editor = "vi"
    with tempfile.NamedTemporaryFile(
        suffix=".md", delete=False, mode="w+"
    ) as temp_file:
        temp_filename = temp_file.name
        try:
            subprocess.run([editor, temp_filename], check=True)
        except subprocess.CalledProcessError as e:
            print(f"Error launching editor: {e}")
            return ""
        temp_file.close()
        try:
            with open(temp_filename, "r") as f:
                edited_text = f.read()
        except IOError as e:
            print(f"Error reading temp file after close: {e}")
            return ""
        try:
            os.remove(temp_filename)
        except OSError as e:
            print(f"Error deleting temporary file: {e}")
        return edited_text


def choose_prompt(argument, file, editor) -> str:
    if argument:
        return argument
    if editor:
        return read_prompt_from_editor()
    if file:
        return read_prompt_from_file(file)
    print("no prompt provided, use -q, -f or -e")
    exit(0)


def history_conversation_print():
    with open(get_history_conversation_path(), "r") as f:
        print(f.read())


def history_conversation_clean():
    os.remove(get_history_conversation_path())


def get_history_conversation() -> list[HistoryElement]:
    path = get_history_conversation_path()
    data = None
    with open(path, "r") as f:
        try:
            data = json.load(f)
        except json.JSONDecodeError as e:
            data = []
    return data


def history_conversation_append(prompt: str, response: str):
    data = get_history_conversation()
    data.append({"prompt": prompt, "response": response})
    with open(get_history_conversation_path(), "w") as f:
        json.dump(data, f, indent=4)


def history_all_append(prompt: str, response: str, model: str):
    now = datetime.now()
    with open(get_history_all_path(), "a") as f:
        f.writelines(
            [
                "--------------------------------------------------------------------------------\n\n",
                f"DATE\n",
                f"{now.strftime('%A %d %B %Y - %H:%M:%S').lower()}\n\n",
                "MODEL\n",
                f"{model}\n\n",
                "PROMPT\n",
                f"{prompt}\n\n",
                "RESPONSE\n",
                f"{response}\n\n",
            ]
        )


def configure_token(api_key: str):
    with open(get_api_key_path(), "+w") as f:
        f.write(api_key)
    print(f"Api key saved to {get_api_key_path()}")


def configure_model(model: str):
    with open(get_model_path(), "+w") as f:
        f.write(model)
    print(f"Model config saved to {get_model_path()}")


def configure_attitude(attitude: str):
    with open(get_attitude_path(), "+w") as f:
        f.write(attitude)
    print(f"Attitude config saved to {get_attitude_path()}")


def print_configuration():
    print(
        f"""
          token:    {get_api_key()}
          model:    {get_model()}
          attitude: {get_attitude()}
          """
    )


def parse_arguments():
    parser = argparse.ArgumentParser(
        f"""

    {app_name} is a command line interface to interact with your chosen AI assistant.

    Configure ai-cli with your token goten from open_router.
    $ {app_name} --configure-token $OPEN_ROUTER_API_KEY

    Send a prompt. 
    $ {app_name} -p "what is the meaning of code" 

    Send a prompt using your favorite editor.
    It uses your editor to enter a prompt, it will be sent uppon quitting the editor.
    $ {app_name} -e

    Ask a prompt written to a file without using the chat history.
    $ {app_name} --history-no --file "path_to_a_file_with_a_prompt_within"

    Print and then delete your chat history.
    $ {app_name} --history-print ; {app_name} --history-clean

    {app_name} has 2 kinds of history:
      - 1 for the current conversation, that need to be deleted often to keep cost low and keep the answers not too biased.
      - 1 that keep a record of all conversations that is never deleted, very useful to search past conversations.
    The all-time-history is located at ~/.config/{app_name}/history_all_time
    $ less ~/.config/{app_name}/history_all_time
    
    """
    )
    parser.add_argument("-p", "--prompt", help="prompt to send to the AI assistant")
    parser.add_argument(
        "-f",
        "--file",
        help="read a prompt from a file",
        default=f"{get_config_path()}/prompt.txt",
    )
    parser.add_argument(
        "-e", "--editor", action="store_true", help="open $EDITOR to enter a prompt"
    )
    parser.add_argument(
        "-hc",
        "--history-clean",
        action="store_true",
        help="clean history of previous message (conversation context) and quit",
    )
    parser.add_argument(
        "-hn",
        "--history-no",
        action="store_true",
        help="ask a prompt to the llm without the history of the previous messages",
    )
    parser.add_argument(
        "-hp",
        "--history-print",
        action="store_true",
        help="print the conversation history and quit.",
    )
    parser.add_argument(
        "-cm",
        "--configure-model",
        help=f'Configure {app_name} model and quit, default is "{default_model}". example: {app_name} -cm "mistralai/mistral-small-3.1-24b-instruct:free"',
    )
    parser.add_argument(
        "-ca",
        "--configure-attitude",
        help=f'Configure {app_name} attitude and quit, default is "{default_attitude}". example: {app_name} -ca "you are a joyful developer assistant"',
    )
    parser.add_argument(
        "-ct",
        "--configure-token",
        help=f"Configure {app_name} by providing your token and quit. example: {app_name} -ct $OPEN_ROUTER_API_TOKEN",
    )
    parser.add_argument(
        "-cp",
        "--configuration-print",
        action="store_true",
        help="Print your configuration and quit.",
    )
    args = parser.parse_args()
    return args


if __name__ == "__main__":
    args = parse_arguments()
    if args.configure_token:
        configure_token(args.configure_token)
        exit(0)
    if args.configure_model:
        configure_model(args.configure_model)
        exit(0)
    if args.configure_attitude:
        configure_attitude(args.configure_attitude)
        exit(0)
    if args.history_print:
        history_conversation_print()
        exit(0)
    if args.history_clean:
        history_conversation_clean()
        exit(0)
    if args.configuration_print:
        print_configuration()
        exit(0)
    prompt = choose_prompt(args.prompt, args.file, args.editor)
    if prompt == "":
        print("no prompt provided")
        exit(0)
    model = get_model()
    attitude = get_attitude()
    print(f"Model: {model}")
    print(f"Prompt: {prompt}")
    history = None
    if not args.history_no:
        history = get_history_conversation()
    response = prompt_ai(prompt, model, attitude, history)
    console = Console()
    md = Markdown(response)
    print("Response:")
    console.print(md)
    if not args.history_no:
        history_conversation_append(prompt, response)
    history_all_append(prompt, response, model)
    print()
